{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFFN(nn.Module):\n",
    "    def __init__(self,ff_input,ff_hiddens,ff_outputs,**kwargs):\n",
    "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
    "        self.dense1=nn.Linear(ff_input,ff_hiddens)\n",
    "        self.dense2=nn.Linear(ff_hiddens,ff_outputs)\n",
    "        self.relu=nn.Relu()\n",
    "\n",
    "    def forward(self,X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNorm(nn.Module):\n",
    "    \"\"\"残差连接后进行层规范化\"\"\"\n",
    "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
    "        super(AddNorm, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(normalized_shape)\n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"Transformer编码器块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "        norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "        dropout, use_bias=False, **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        self.attention = d2l.MultiHeadAttention(\n",
    "        key_size, query_size, value_size, num_hiddens, num_heads, dropout,\n",
    "        use_bias)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(\n",
    "        ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "        def forward(self, X, valid_lens):\n",
    "            Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n",
    "            return self.addnorm2(Y, self.ffn(Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(d2l.Encoder):\n",
    "    def __init__(self, vocab_size,\n",
    "        num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "        num_heads, num_layers, dropout, use_bias=False, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens=num_hiddens\n",
    "        self.embedding=nn.embedding(vocab_size,num_hiddens)\n",
    "        self.pos_encoding=d2l.PositionalEncoding(num_hiddens,dropout)\n",
    "        self.blk=nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blk.add_module(\"block\"+str(i),EncoderBlock(num_hiddens,\n",
    "            norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "            dropout,use_bias=False))\n",
    "    def forward(self,X,valid_lens):\n",
    "        X=self.pos_encoding(self.embedding(X)*math.sqrt(self.num_hiddens))\n",
    "        self.attention_weights = [None] * len(self.blks)\n",
    "        for i , blk in enumerate(self.blk):\n",
    "            X=blk(X,valid_lens)\n",
    "            self.attention_weights[\n",
    "            i] = blk.attention.attention.attention_weights\n",
    "        return X\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在训练阶段，其输出序列的所有位置（时\n",
    "间步）的词元都是已知的；然而，在预测阶段，其输出序列的词元是逐个生成的。因此，在任何解码器时间\n",
    "步中，只有生成的词元才能用于解码器的自注意力计算中。为了在解码器中保留自回归的属性，其掩蔽自注\n",
    "意力设定了参数dec_valid_lens，以便任何查询都只会与解码器中所有已经生成词元的位置（即直到该查询\n",
    "位置为止）进行注意力计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"解码器中第i个块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "        norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "        dropout, i, **kwargs):\n",
    "        super(DecoderBlock, self).__init__(**kwargs)\n",
    "        self.i = i\n",
    "        self.attention1 = d2l.MultiHeadAttention(\n",
    "        key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.attention2 = d2l.MultiHeadAttention(\n",
    "        key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens,\n",
    "        num_hiddens)\n",
    "        self.addnorm3 = AddNorm(norm_shape, dropout)\n",
    "    def forward(self,X,state):\n",
    "        enc_outputs,enc_valid_lens=state[0],state[1]\n",
    "        if state[2][self.i] is None:\n",
    "            key_values=X\n",
    "        else:\n",
    "            key_values=torch.cat((state[2][self.i],X),axis=1)\n",
    "            state[2][self.i]=key_values\n",
    "        if self.training:  # 上面有解释\n",
    "            batch_size,num_steps,_=X.shape\n",
    "            dec_valid_lens= torch.arange(1,num_steps+1,device=X.device).repeat(batch_size,1)\n",
    "        else:\n",
    "            dec_valid_lens=None\n",
    "\n",
    "        X2=self.attention1(X,key_values,key_values,dec_valid_lens)\n",
    "        Y= self.addnorm1(X,X2)\n",
    "        Y2=self.attention2(Y,enc_outputs,enc_outputs,enc_valid_lens)\n",
    "        Z=self.addnorm2(Y,Y2)\n",
    "        return self.addnorm3(self.ffn(Z),Z) ,state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(d2l.AttentionDecoder):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "        num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "        num_heads, num_layers, dropout, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),\n",
    "            DecoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "            norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "            num_heads, dropout, i))\n",
    "            self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "    def init_state(self,enc_outputs,enc_valid_lens,*args):\n",
    "        return [enc_outputs,enc_valid_lens,[None]*self.num_layers]\n",
    "    def forward(self,X,state):\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self._attention_weights = [[None] * len(self.blks) for _ in range (2)]\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X, state = blk(X, state)\n",
    "            # 解码器自注意力权重\n",
    "            self._attention_weights[0][\n",
    "            i] = blk.attention1.attention.attention_weights\n",
    "            # “编码器－解码器”自注意力权重\n",
    "            self._attention_weights[1][\n",
    "            i] = blk.attention2.attention.attention_weights\n",
    "        return self.dense(X), state\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hiddens, num_layers, dropout, batch_size, num_steps = 32, 2, 0.1, 64, 10\n",
    "lr, num_epochs, device = 0.005, 200, d2l.try_gpu()\n",
    "ffn_num_input, ffn_num_hiddens, num_heads = 32, 64, 4\n",
    "key_size, query_size, value_size = 32, 32, 32\n",
    "norm_shape = [32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TransformerEncoder.__init__() takes from 9 to 10 positional arguments but 12 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train_iter, src_vocab, tgt_vocab \u001b[38;5;241m=\u001b[39m d2l\u001b[38;5;241m.\u001b[39mload_data_nmt(batch_size, num_steps)\n\u001b[0;32m----> 2\u001b[0m encoder \u001b[38;5;241m=\u001b[39m \u001b[43mTransformerEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc_vocab\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_hiddens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnorm_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mffn_num_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mffn_num_hiddens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m decoder \u001b[38;5;241m=\u001b[39m TransformerDecoder(\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mlen\u001b[39m(tgt_vocab), key_size, query_size, value_size, num_hiddens,\n\u001b[1;32m      7\u001b[0m norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n\u001b[1;32m      8\u001b[0m num_layers, dropout)\n\u001b[1;32m      9\u001b[0m net \u001b[38;5;241m=\u001b[39m d2l\u001b[38;5;241m.\u001b[39mEncoderDecoder(encoder, decoder)\n",
      "\u001b[0;31mTypeError\u001b[0m: TransformerEncoder.__init__() takes from 9 to 10 positional arguments but 12 were given"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)\n",
    "encoder = TransformerEncoder(len(src_vocab), key_size, query_size, value_size, num_hiddens,\n",
    "    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "    num_layers, dropout)\n",
    "decoder = TransformerDecoder(\n",
    "len(tgt_vocab), key_size, query_size, value_size, num_hiddens,\n",
    "norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "num_layers, dropout)\n",
    "net = d2l.EncoderDecoder(encoder, decoder)\n",
    "d2l.train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [1, 2, 3]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
